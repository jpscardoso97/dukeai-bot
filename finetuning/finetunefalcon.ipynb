{"metadata":{"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Train base LLAMA-2-7B for chat using Guanaco dataset (OpenAssistant subset)","metadata":{}},{"cell_type":"code","source":"!pip install -q datasets==2.16.0 bitsandbytes einops peft trl","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:01:22.885043Z","iopub.execute_input":"2024-03-29T18:01:22.885816Z","iopub.status.idle":"2024-03-29T18:01:36.024954Z","shell.execute_reply.started":"2024-03-29T18:01:22.885763Z","shell.execute_reply":"2024-03-29T18:01:36.023719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport wandb\n\nfrom datasets import load_dataset\nfrom huggingface_hub import login\nfrom peft import LoraConfig, PeftModel, get_peft_model\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments\nfrom trl import SFTTrainer\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"hugging-face-token\")\nwandb_key = user_secrets.get_secret(\"wandb-key\")","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:29:52.895181Z","iopub.execute_input":"2024-03-29T18:29:52.895829Z","iopub.status.idle":"2024-03-29T18:29:53.209129Z","shell.execute_reply.started":"2024-03-29T18:29:52.895796Z","shell.execute_reply":"2024-03-29T18:29:53.207951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\n!wandb login $wandb_key","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:29:55.338876Z","iopub.execute_input":"2024-03-29T18:29:55.339800Z","iopub.status.idle":"2024-03-29T18:29:57.343686Z","shell.execute_reply.started":"2024-03-29T18:29:55.339748Z","shell.execute_reply":"2024-03-29T18:29:57.342400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_name = \"timdettmers/openassistant-guanaco\"\ndataset = load_dataset(dataset_name, split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:01:36.034297Z","iopub.execute_input":"2024-03-29T18:01:36.034633Z","iopub.status.idle":"2024-03-29T18:01:37.189167Z","shell.execute_reply.started":"2024-03-29T18:01:36.034608Z","shell.execute_reply":"2024-03-29T18:01:37.188317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:15:14.347189Z","iopub.execute_input":"2024-03-29T18:15:14.347633Z","iopub.status.idle":"2024-03-29T18:15:14.356232Z","shell.execute_reply.started":"2024-03-29T18:15:14.347600Z","shell.execute_reply":"2024-03-29T18:15:14.355095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_id = \"ybelkada/falcon-7b-sharded-bf16\" # 16-bit sharded falcon\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id, \n    quantization_config=bnb_config, \n    device_map=\"auto\",\n    trust_remote_code=True)\n\nqlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\n        \"query_key_value\",\n        #\"dense\",\n        #\"dense_h_to_4h\",\n        #\"dense_4h_to_h\",\n    ],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, qlora_config)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntokenizer.pad_token = tokenizer.eos_token\n\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:15:15.797758Z","iopub.execute_input":"2024-03-29T18:15:15.798505Z","iopub.status.idle":"2024-03-29T18:15:32.036187Z","shell.execute_reply.started":"2024-03-29T18:15:15.798472Z","shell.execute_reply":"2024-03-29T18:15:32.034622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir = \"/kaggle/working/model/\"\noptim = \"paged_adamw_32bit\"\nsave_steps = 10\nlogging_steps = 10\nlearning_rate = 2e-4\n\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,\n    auto_find_batch_size=True,\n    #push_to_hub=True,\n    optim=optim,\n    save_strategy=\"epoch\",\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    fp16=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:16:29.409245Z","iopub.execute_input":"2024-03-29T18:16:29.409833Z","iopub.status.idle":"2024-03-29T18:16:29.419826Z","shell.execute_reply.started":"2024-03-29T18:16:29.409800Z","shell.execute_reply":"2024-03-29T18:16:29.418615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_seq_length = 512\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    peft_config=qlora_config,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:16:31.630410Z","iopub.execute_input":"2024-03-29T18:16:31.630795Z","iopub.status.idle":"2024-03-29T18:16:31.693053Z","shell.execute_reply.started":"2024-03-29T18:16:31.630752Z","shell.execute_reply":"2024-03-29T18:16:31.691911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, module in trainer.model.named_modules():\n    if \"norm\" in name:\n        module = module.to(torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:16:44.673999Z","iopub.execute_input":"2024-03-29T18:16:44.674755Z","iopub.status.idle":"2024-03-29T18:16:44.687382Z","shell.execute_reply.started":"2024-03-29T18:16:44.674724Z","shell.execute_reply":"2024-03-29T18:16:44.686318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:16:48.499250Z","iopub.execute_input":"2024-03-29T18:16:48.499642Z","iopub.status.idle":"2024-03-29T18:20:36.943871Z","shell.execute_reply.started":"2024-03-29T18:16:48.499612Z","shell.execute_reply":"2024-03-29T18:20:36.941990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# push to hub\ntrainer.save_model(\"falcon-7b-guanaco-16bit\")\n\nfine_tuned_model = PeftModel.from_pretrained(\"falcon-7b-guanaco-16bit\")\n\nadapters_path = 'falcon-guanaco'\n\nfine_tuned_model.push_to_hub(\"jpscardoso/falcon-7b-guanaco-16bit\", token=\"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\")","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:03:34.099122Z","iopub.status.idle":"2024-03-29T18:03:34.099908Z","shell.execute_reply.started":"2024-03-29T18:03:34.099625Z","shell.execute_reply":"2024-03-29T18:03:34.099647Z"},"trusted":true},"execution_count":null,"outputs":[]}]}