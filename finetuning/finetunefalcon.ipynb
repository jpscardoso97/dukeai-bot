{"cells":[{"cell_type":"markdown","metadata":{},"source":["Train base LLAMA-2-7B for chat using Guanaco dataset (OpenAssistant subset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T18:01:22.885816Z","iopub.status.busy":"2024-03-29T18:01:22.885043Z","iopub.status.idle":"2024-03-29T18:01:36.024954Z","shell.execute_reply":"2024-03-29T18:01:36.023719Z","shell.execute_reply.started":"2024-03-29T18:01:22.885763Z"},"trusted":true},"outputs":[],"source":["!pip install -q datasets==2.16.0 bitsandbytes einops peft trl"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T18:29:52.895829Z","iopub.status.busy":"2024-03-29T18:29:52.895181Z","iopub.status.idle":"2024-03-29T18:29:53.209129Z","shell.execute_reply":"2024-03-29T18:29:53.207951Z","shell.execute_reply.started":"2024-03-29T18:29:52.895796Z"},"trusted":true},"outputs":[],"source":["import torch\n","import wandb\n","\n","from datasets import load_dataset\n","from huggingface_hub import login\n","from peft import LoraConfig, PeftModel, get_peft_model\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments\n","from trl import SFTTrainer\n","from kaggle_secrets import UserSecretsClient\n","\n","user_secrets = UserSecretsClient()\n","secret_value_0 = user_secrets.get_secret(\"hugging-face-token\")\n","wandb_key = user_secrets.get_secret(\"wandb-key\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T18:29:55.339800Z","iopub.status.busy":"2024-03-29T18:29:55.338876Z","iopub.status.idle":"2024-03-29T18:29:57.343686Z","shell.execute_reply":"2024-03-29T18:29:57.342400Z","shell.execute_reply.started":"2024-03-29T18:29:55.339748Z"},"trusted":true},"outputs":[],"source":["from kaggle_secrets import UserSecretsClient\n","\n","!wandb login $wandb_key"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T18:01:36.034633Z","iopub.status.busy":"2024-03-29T18:01:36.034297Z","iopub.status.idle":"2024-03-29T18:01:37.189167Z","shell.execute_reply":"2024-03-29T18:01:37.188317Z","shell.execute_reply.started":"2024-03-29T18:01:36.034608Z"},"trusted":true},"outputs":[],"source":["dataset_name = \"timdettmers/openassistant-guanaco\"\n","dataset = load_dataset(dataset_name, split=\"train\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T18:15:14.347633Z","iopub.status.busy":"2024-03-29T18:15:14.347189Z","iopub.status.idle":"2024-03-29T18:15:14.356232Z","shell.execute_reply":"2024-03-29T18:15:14.355095Z","shell.execute_reply.started":"2024-03-29T18:15:14.347600Z"},"trusted":true},"outputs":[],"source":["def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T18:15:15.798505Z","iopub.status.busy":"2024-03-29T18:15:15.797758Z","iopub.status.idle":"2024-03-29T18:15:32.036187Z","shell.execute_reply":"2024-03-29T18:15:32.034622Z","shell.execute_reply.started":"2024-03-29T18:15:15.798472Z"},"trusted":true},"outputs":[],"source":["model_id = \"ybelkada/falcon-7b-sharded-bf16\" # 16-bit sharded falcon\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_id, \n","    quantization_config=bnb_config, \n","    device_map=\"auto\",\n","    trust_remote_code=True)\n","\n","qlora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    target_modules=[\n","        \"query_key_value\",\n","        #\"dense\",\n","        #\"dense_h_to_4h\",\n","        #\"dense_4h_to_h\",\n","    ],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","model = get_peft_model(model, qlora_config)\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","print_trainable_parameters(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T18:16:29.409833Z","iopub.status.busy":"2024-03-29T18:16:29.409245Z","iopub.status.idle":"2024-03-29T18:16:29.419826Z","shell.execute_reply":"2024-03-29T18:16:29.418615Z","shell.execute_reply.started":"2024-03-29T18:16:29.409800Z"},"trusted":true},"outputs":[],"source":["output_dir = \"/kaggle/working/model/\"\n","optim = \"paged_adamw_32bit\"\n","save_steps = 10\n","logging_steps = 10\n","learning_rate = 2e-4\n","\n","training_arguments = TrainingArguments(\n","    output_dir=output_dir,\n","    auto_find_batch_size=True,\n","    #push_to_hub=True,\n","    optim=optim,\n","    save_strategy=\"epoch\",\n","    logging_steps=logging_steps,\n","    learning_rate=learning_rate,\n","    fp16=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T18:16:31.630795Z","iopub.status.busy":"2024-03-29T18:16:31.630410Z","iopub.status.idle":"2024-03-29T18:16:31.693053Z","shell.execute_reply":"2024-03-29T18:16:31.691911Z","shell.execute_reply.started":"2024-03-29T18:16:31.630752Z"},"trusted":true},"outputs":[],"source":["max_seq_length = 512\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=dataset,\n","    peft_config=qlora_config,\n","    dataset_text_field=\"text\",\n","    max_seq_length=max_seq_length,\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T18:16:44.674755Z","iopub.status.busy":"2024-03-29T18:16:44.673999Z","iopub.status.idle":"2024-03-29T18:16:44.687382Z","shell.execute_reply":"2024-03-29T18:16:44.686318Z","shell.execute_reply.started":"2024-03-29T18:16:44.674724Z"},"trusted":true},"outputs":[],"source":["for name, module in trainer.model.named_modules():\n","    if \"norm\" in name:\n","        module = module.to(torch.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T18:16:48.499642Z","iopub.status.busy":"2024-03-29T18:16:48.499250Z","iopub.status.idle":"2024-03-29T18:20:36.943871Z","shell.execute_reply":"2024-03-29T18:20:36.941990Z","shell.execute_reply.started":"2024-03-29T18:16:48.499612Z"},"trusted":true},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:03:34.099122Z","iopub.status.idle":"2024-03-29T18:03:34.099908Z","shell.execute_reply":"2024-03-29T18:03:34.099647Z","shell.execute_reply.started":"2024-03-29T18:03:34.099625Z"},"trusted":true},"outputs":[],"source":["# push to hub\n","trainer.save_model(\"falcon-7b-guanaco-16bit\")\n","\n","fine_tuned_model = PeftModel.from_pretrained(\"falcon-7b-guanaco-16bit\")\n","\n","adapters_path = 'falcon-guanaco'\n","\n","fine_tuned_model.push_to_hub(\"jpscardoso/falcon-7b-guanaco-16bit\", token=\"\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
